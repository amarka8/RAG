{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "import faiss\n",
    "import torch\n",
    "# from tqdm import tqdm\n",
    "\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "\n",
    "# from abc import abstractmethod\n",
    "# import concurrent.futures\n",
    "# from concurrent.futures import ThreadPoolExecutor\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain import hub\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.documents import Document\n",
    "from typing_extensions import List, TypedDict\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Normally User-Inputted Args\"\"\"\n",
    "dataset = 'musique'\n",
    "model_label = 'SBERT'\n",
    "unit = 'hippo'\n",
    "\n",
    "vector_path = f'data/{dataset}/{dataset}_{model_label}_{unit}_vectors_norm.npy'\n",
    "index_path = f'data/{dataset}/{dataset}_{model_label}_{unit}_ip_norm.index'\n",
    "\n",
    "#check if index has been built, otherwise build it using Sentence BERT\n",
    "if(os.path.isfile(index_path)):\n",
    "    if dataset == 'musique':\n",
    "        faiss_index = faiss.read_index('data/musique/musique_facebook_contriever_proposition_ip_norm.index')\n",
    "    else:\n",
    "        faiss_index = faiss.read_index('data/2wikimultihopqa/2wikimultihopqa_facebook_contriever_proposition_ip_norm.index')\n",
    "else:\n",
    "    corpus_contents = []\n",
    "    if dataset == 'musique':\n",
    "        corpus = json.load(open('data/musique_corpus.json', 'r'))\n",
    "    elif dataset == '2wikimultihopqa':\n",
    "        corpus = json.load(open('data/2wikimultihopqa_corpus.json', 'r'))\n",
    "    for item in corpus:\n",
    "        corpus_contents.append(item['title'] + '\\n' + item['text'])\n",
    "    model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "    sentence_embeddings = model.encode(corpus_contents)\n",
    "    # sentence_embeddings.shape #dimension\n",
    "    nlist = 50  # how many cells\n",
    "    quantizer = faiss.IndexFlatL2(d)\n",
    "    index = faiss.IndexIVFFlat(quantizer, d, nlist)\n",
    "    index.train(sentence_embeddings)\n",
    "    print(f'status of index training: {index.is_trained}')\n",
    "    index.add(sentence_embeddings)\n",
    "    print(f'number of embeddings indexed: {index.ntotal}')\n",
    "    index.nprobe = 10\n",
    "    fp = open(index_path, 'w')\n",
    "    faiss.write_index(index, index_path)\n",
    "    print('index saved to {}'.format(index_path))\n",
    "    print('index size: {}'.format(index.ntotal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0   15    5 3237 3467 9778 4049   12]\n",
      " [   1 1151 5183 1182 9383 5416    2    6]\n",
      " [   2 1151    6 1401 1392 1157 1182    9]\n",
      " [   3   10   17 1153 1161 4157 1148    7]\n",
      " [   4   15 4157 1161 4816 1148 1162 4812]]\n",
      "[[ 0.       62.610523 68.035484 69.34587  70.68082  75.65885  76.97651\n",
      "  81.67229 ]\n",
      " [ 0.       62.02321  74.02515  75.6939   78.519455 81.68285  82.059555\n",
      "  85.76392 ]\n",
      " [ 0.       55.484562 57.086422 59.82897  61.155815 65.204315 67.402985\n",
      "  67.54554 ]\n",
      " [ 0.       26.270998 37.556023 45.910477 49.71403  50.727356 52.845726\n",
      "  57.460052]\n",
      " [ 0.       78.98981  82.67015  87.23726  89.43833  91.34279  92.65403\n",
      "  92.92813 ]]\n"
     ]
    }
   ],
   "source": [
    "#sanity check\n",
    "k = 8\n",
    "# xq = model.encode([\"When was the person who Messi's goals in Copa del Rey compared to get signed by Barcelona?\"])\n",
    "# %%time\n",
    "D, I = index.search(sentence_embeddings[:5], k)  # search\n",
    "print(I)\n",
    "print(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4055 9017 4399 1146    2    6   14 9018]]\n",
      "[[141.59459 157.06607 159.7016  162.37042 165.21324 165.46158 168.73495\n",
      "  170.67453]]\n"
     ]
    }
   ],
   "source": [
    "query = model.encode([\"When was the person who Messi's goals in Copa del Rey compared to get signed by Barcelona?\"])\n",
    "k = 8\n",
    "D, I = index.search(query, k)  # search\n",
    "print(I)\n",
    "print(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv('.env')\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "prompt = hub.pull(\"rlm/rag-prompt\", api_key = os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"), additional_kwargs={})])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"User-inputted arg\"\"\"\n",
    "max_steps = 1\n",
    "\n",
    "if dataset == 'musique':\n",
    "    data = json.load(open('data/musique.json', 'r'))\n",
    "    if corpus is not None:\n",
    "        corpus = json.load(open('data/musique_corpus.json', 'r'))\n",
    "    # prompt_path = 'data/ircot_prompts/musique/gold_with_3_distractors_context_cot_qa_codex.txt'\n",
    "    max_steps = max_steps if max_steps is not None else 4\n",
    "elif dataset == '2wikimultihopqa':\n",
    "    data = json.load(open('data/2wikimultihopqa.json', 'r'))\n",
    "    if corpus is not None:\n",
    "        corpus = json.load(open('data/2wikimultihopqa_corpus.json', 'r'))\n",
    "    # prompt_path = 'data/ircot_prompts/2wikimultihopqa/gold_with_3_distractors_context_cot_qa_codex.txt'\n",
    "    max_steps = max_steps if max_steps is not None else 2\n",
    "else:\n",
    "    raise NotImplementedError(f'Dataset {dataset} not implemented')\n",
    "\n",
    "top_k = 100\n",
    "k_list = [1, 2, 5, 8]\n",
    "total_recall = {k: 0 for k in k_list}\n",
    "llm = ChatOpenAI(model='gpt-3.5-turbo-1106')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(state: State):\n",
    "    D, I = faiss_index.search(state[\"question\"], top_k)\n",
    "    return {\"context\": I.tolist()[0]}\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "faiss_1.8.0_new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
