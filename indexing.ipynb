{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amarkanaka/miniconda3/envs/faiss_1.8.0_new_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# import sys\n",
    "\n",
    "# from src.processing import mean_pooling, mean_pooling_embedding_with_normalization\n",
    "\n",
    "# sys.path.append('.')\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "import faiss\n",
    "import torch\n",
    "# from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embeddings Model is a mapping from chunks of max length 512 tokens -> R^768 ???\n",
    "dim = 768\n",
    "#normalize embeddings\n",
    "norm = True\n",
    "dataset = 'musique'\n",
    "# unit = 'proposition'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_label = 'facebook_contriever'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_path = f'data/{dataset}/{dataset}_{model_label}_proposition_vectors_norm.npy'\n",
    "index_path = f'data/{dataset}/{dataset}_{model_label}_proposition_ip_norm.index'\n",
    "if(os.path.isfile(vector_path)):\n",
    "    vectors = np.load(vector_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/musique/musique_facebook_contriever_proposition_vectors_norm.npy'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus size: 11656\n"
     ]
    }
   ],
   "source": [
    "if dataset == 'musique':\n",
    "    corpus = json.load(open('data/musique_proposition_corpus.json', 'r'))\n",
    "elif dataset == '2wikimultihopqa':\n",
    "    corpus = json.load(open('data/2wikimultihopqa_proposition_corpus.json', 'r'))\n",
    "corpus_contents = []\n",
    "for item in corpus:\n",
    "    corpus_contents.append(item['title'] + '\\n' + item['propositions'])\n",
    "print('corpus size: {}'.format(len(corpus_contents)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "525.25\n",
      "31.25\n",
      "149.56335792724778\n"
     ]
    }
   ],
   "source": [
    "total_len = 0\n",
    "max_len = 0\n",
    "min_len = 1000000\n",
    "for line in corpus_contents:\n",
    "    total_len += len(line)\n",
    "    if len(line) > max_len:\n",
    "        max_len = len(line)\n",
    "    if len(line) < min_len:\n",
    "        min_len = len(line)\n",
    "print(max_len / 4)\n",
    "print(min_len / 4)\n",
    "print((total_len / len(corpus_contents)) / 4)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(vector_path):\n",
    "    print('Loading existing vectors:', vector_path)\n",
    "    vectors = np.load(vector_path)\n",
    "    print('Vectors loaded:', len(vectors))\n",
    "else:\n",
    "    # load model\n",
    "    tokenizer = AutoTokenizer.from_pretrained('facebook/contriever')\n",
    "    model = AutoModel.from_pretrained('facebook/contriever')\n",
    "    # Check if multiple GPUs are available and if so, use them all\n",
    "    if not torch.backends.mps.is_available():\n",
    "        if not torch.backends.mps.is_built():\n",
    "            print(\"MPS not available because the current PyTorch install was not \"\n",
    "                \"built with MPS enabled.\")\n",
    "        else:\n",
    "            print(\"MPS not available because the current MacOS version is not 12.3+ \"\n",
    "                \"and/or you do not have an MPS-enabled device on this machine.\")\n",
    "    else:\n",
    "        # print(\"device available\")\n",
    "        mps_device = torch.device(\"mps\")    \n",
    "        model.to(mps_device)\n",
    "        model = torch.nn.DataParallel(model)\n",
    "    #test batch size = 16 and batch size = 32 \n",
    "    batch_size = 16\n",
    "    vectors = np.zeros((len(corpus_contents), dim))\n",
    "    #get batch_size # of entries from corpus_contents, tokenize and embed them in 768 dimensional space\n",
    "    # for idx in range(0, len(corpus_contents), batch_size):\n",
    "    #     end_idx = min(idx + batch_size, len(corpus_contents))\n",
    "    #     seqs = corpus_contents[idx:end_idx]\n",
    "        # tokens = tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Lionel Messi\\nLionel Messi spent a year at Barcelona's youth academy, La Masia. Messi was enrolled in the Royal Spanish Football Federation (RFEF) in February 2002. Messi played in all competitions. Messi befriended his teammates, Cesc Fàbregas and Gerard Piqué. Cesc Fàbregas and Gerard Piqué were among Lionel Messi's teammates. Messi completed his growth hormone treatment aged 14. Messi became an integral part of the Baby Dream Team, Barcelona's greatest-ever youth side. During his first full season (2002-03), Messi was top scorer with 36 goals in 30 games for the Cadetes A. The Cadetes A won an unprecedented treble of the league and both the Spanish and Catalan cups. The Copa Catalunya final was a 4-1 victory over Espanyol. The Copa Catalunya final became known in club lore as the partido de la máscara, the final of the mask. Messi suffered a broken cheekbone during a league match. Messi was allowed to start the game on the condition that he wear a plastic protector. Messi was hindered by the plastic protector. Messi took off the plastic protector and scored two goals in 10 minutes before his substitution. At the close of the season, Messi received an offer to join Arsenal. Messi's first offer to join Arsenal was from a foreign club. Cesc Fàbregas and Gerard Piqué left for England. Messi chose to remain in Barcelona.\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_contents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"FC Barcelona\\nFC Barcelona was the favourites and started strongly. Barcelona finished the 2006-07 season without trophies. A pre-season US tour was blamed for a string of injuries to key players. Leading scorer Eto'o was injured during the US tour. Rising star Lionel Messi was injured during the US tour. There was open feuding between Eto'o and coach Frank Rijkaard and Ronaldinho. Ronaldinho admitted that a lack of fitness affected his form. In La Liga, Barcelona were in first place for much of the season. Inconsistency in the New Year saw Real Madrid overtake Barcelona to become champions. Barcelona advanced to the semi-finals of the Copa del Rey. Barcelona won the first leg against Getafe 5-2. A goal from Messi brought comparison to Diego Maradona's goal of the century. Barcelona lost the second leg 4-1. Barcelona took part in the 2006 FIFA Club World Cup. Barcelona was beaten by a late goal in the final against Brazilian side Internacional. In the Champions League, Barcelona were knocked out of the competition in the last 16 by eventual runners-up Liverpool on away goals.\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_contents[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1339"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#longer sequence\n",
    "len(corpus_contents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1091"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shorter sequence\n",
    "len(corpus_contents[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_ex = tokenizer(corpus_contents[:2],padding = True, truncation= True, return_tensors='pt').to(mps_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_ex[\"input_ids\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.0193, -0.2598, -0.0947,  ...,  0.1957, -0.2767, -0.0861],\n",
       "         [-0.2650,  0.2685,  0.2683,  ...,  0.0458,  0.0605, -0.0593],\n",
       "         [-0.0595, -0.1592,  0.0049,  ..., -0.0088,  0.0349,  0.0666],\n",
       "         ...,\n",
       "         [-0.1642,  0.3410,  0.1903,  ..., -0.1007, -0.2093, -0.4115],\n",
       "         [ 0.1654, -0.0760,  0.0687,  ...,  0.1888, -0.0068,  0.1188],\n",
       "         [ 0.0531, -0.2163,  0.0448,  ...,  0.1647, -0.0648, -0.0252]],\n",
       "\n",
       "        [[ 0.1521, -0.1501, -0.1869,  ..., -0.1612, -0.0992, -0.0393],\n",
       "         [-0.5969, -0.1441,  0.2693,  ..., -0.3138,  0.1886, -0.6843],\n",
       "         [-0.0079,  0.3074,  0.1848,  ..., -0.0957, -0.0184, -0.3032],\n",
       "         ...,\n",
       "         [ 0.2553, -1.0877,  0.1557,  ...,  0.3257,  0.0293,  0.0979],\n",
       "         [ 0.5607, -0.9700,  0.0770,  ...,  0.2181,  0.0424, -0.0582],\n",
       "         [ 0.6028, -1.2719,  0.0332,  ...,  0.3162,  0.0034,  0.0091]]],\n",
       "       device='mps:0', grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 0.1124, -0.0594, -0.0937,  ...,  0.0199, -0.0089, -0.1202],\n",
       "        [-0.0391, -0.0276, -0.0230,  ...,  0.0389, -0.0313, -0.0630]],\n",
       "       device='mps:0', grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model(**encoding_ex)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Originally, we have 315 token IDS to describe our tokenization of the first line in the corpus and the second line in the corpus. We then map each token to a 768 dimensional vector. The dimension increases because we take a \"bag of words approach\" and create token-level embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 315, 768])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0193, -0.2598, -0.0947,  ...,  0.1957, -0.2767, -0.0861],\n",
       "         [-0.2650,  0.2685,  0.2683,  ...,  0.0458,  0.0605, -0.0593],\n",
       "         [-0.0595, -0.1592,  0.0049,  ..., -0.0088,  0.0349,  0.0666],\n",
       "         ...,\n",
       "         [-0.1642,  0.3410,  0.1903,  ..., -0.1007, -0.2093, -0.4115],\n",
       "         [ 0.1654, -0.0760,  0.0687,  ...,  0.1888, -0.0068,  0.1188],\n",
       "         [ 0.0531, -0.2163,  0.0448,  ...,  0.1647, -0.0648, -0.0252]],\n",
       "\n",
       "        [[ 0.1521, -0.1501, -0.1869,  ..., -0.1612, -0.0992, -0.0393],\n",
       "         [-0.5969, -0.1441,  0.2693,  ..., -0.3138,  0.1886, -0.6843],\n",
       "         [-0.0079,  0.3074,  0.1848,  ..., -0.0957, -0.0184, -0.3032],\n",
       "         ...,\n",
       "         [ 0.2553, -1.0877,  0.1557,  ...,  0.3257,  0.0293,  0.0979],\n",
       "         [ 0.5607, -0.9700,  0.0770,  ...,  0.2181,  0.0424, -0.0582],\n",
       "         [ 0.6028, -1.2719,  0.0332,  ...,  0.3162,  0.0034,  0.0091]]],\n",
       "       device='mps:0', grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0193, -0.2598, -0.0947,  ...,  0.1957, -0.2767, -0.0861],\n",
       "         [-0.2650,  0.2685,  0.2683,  ...,  0.0458,  0.0605, -0.0593],\n",
       "         [-0.0595, -0.1592,  0.0049,  ..., -0.0088,  0.0349,  0.0666],\n",
       "         ...,\n",
       "         [-0.1642,  0.3410,  0.1903,  ..., -0.1007, -0.2093, -0.4115],\n",
       "         [ 0.1654, -0.0760,  0.0687,  ...,  0.1888, -0.0068,  0.1188],\n",
       "         [ 0.0531, -0.2163,  0.0448,  ...,  0.1647, -0.0648, -0.0252]],\n",
       "\n",
       "        [[ 0.1521, -0.1501, -0.1869,  ..., -0.1612, -0.0992, -0.0393],\n",
       "         [-0.5969, -0.1441,  0.2693,  ..., -0.3138,  0.1886, -0.6843],\n",
       "         [-0.0079,  0.3074,  0.1848,  ..., -0.0957, -0.0184, -0.3032],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
       "       device='mps:0', grad_fn=<MaskedFillBackward0>)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0].masked_fill(~encoding_ex[\"attention_mask\"][...,None].bool(),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0237, -0.0938,  0.0261,  ...,  0.0126, -0.0239, -0.0051],\n",
       "        [ 0.2324, -0.2980, -0.0321,  ..., -0.0242, -0.0004, -0.0803]],\n",
       "       device='mps:0', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0].sum(dim=1)/encoding_ex[\"attention_mask\"].sum(dim=1).unsqueeze(-1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "faiss_1.8.0_new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
